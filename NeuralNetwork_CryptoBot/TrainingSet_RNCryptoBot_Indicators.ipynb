{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samueltg92/anaconda3/envs/algotrading/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/home/samueltg92/anaconda3/envs/algotrading/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/home/samueltg92/anaconda3/envs/algotrading/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/home/samueltg92/anaconda3/envs/algotrading/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/home/samueltg92/anaconda3/envs/algotrading/lib/python3.10/site-packages/ta/trend.py:787: RuntimeWarning: invalid value encountered in subtract\n",
      "  directional_index = 100 * np.abs((dip - din) / (dip + din))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data_scaled[\u001b[39m'\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[39m# Dividir los datos en conjuntos de entrenamiento y validación\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m X_train, X_val, y_train, y_val \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[1;32m     54\u001b[0m \u001b[39m# Definir el modelo de red neuronal\u001b[39;00m\n\u001b[1;32m     55\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m     56\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(\u001b[39m100\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, input_shape\u001b[39m=\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m)),  \u001b[39m# Aumenté las unidades en la LSTM\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(\u001b[39m50\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),  \u001b[39m# Añadí una segunda capa LSTM\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m50\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),  \u001b[39m# Añadí una capa densa intermedia\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)\n\u001b[1;32m     60\u001b[0m ])\n",
      "File \u001b[0;32m~/anaconda3/envs/algotrading/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m   2564\u001b[0m )\n\u001b[1;32m   2566\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m   2567\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/algotrading/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2233\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[1;32m   2235\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2240\u001b[0m     )\n\u001b[1;32m   2242\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import ta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from binance.client import Client\n",
    "\n",
    "# Autenticación en la API de Binance\n",
    "api_key = 'GFFbe5wk9HnG4eqS1Wlw54WkHrEExQ11yslR3qx6fFTapoXfvHSgcixcRLrB7Cgy'\n",
    "api_secret = 'lUJlWrU7EhHR3YdcbTFqtdCwYc8qIw5NRUhqYATQ7DtjujYSO9nLZrPXINsvMdLc'\n",
    "client = Client(api_key, api_secret)\n",
    "\n",
    "# Obtención de los datos históricos de precios de Bitcoin\n",
    "klines = client.futures_historical_klines(\"BTCUSDT\", Client.KLINE_INTERVAL_1HOUR, \"13 year ago UTC\")\n",
    "\n",
    "# Creación de un dataframe con los datos\n",
    "data = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'])\n",
    "\n",
    "# Conversión de los precios y volumen a float\n",
    "data['open'] = data['open'].astype(float)\n",
    "data['high'] = data['high'].astype(float)\n",
    "data['low'] = data['low'].astype(float)\n",
    "data['close'] = data['close'].astype(float)\n",
    "data['volume'] = data['volume'].astype(float)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = pd.DataFrame(scaler.fit_transform(data[['open', 'high', 'low', 'close', 'volume']]), columns=['open', 'high', 'low', 'close', 'volume'])\n",
    "\n",
    "# Procesar los datos para la entrada del modelo\n",
    "data_scaled['t-24'] = data_scaled['close'].shift(24)\n",
    "\n",
    "# Calcular indicadores técnicos\n",
    "data_scaled['RSI'] = ta.momentum.RSIIndicator(data_scaled['close']).rsi()\n",
    "data_scaled['MACD'] = ta.trend.MACD(data_scaled['close']).macd_diff()\n",
    "data_scaled['EMA_100'] = ta.trend.EMAIndicator(data_scaled['close'], 100).ema_indicator()\n",
    "data_scaled['EMA_200'] = ta.trend.EMAIndicator(data_scaled['close'], 200).ema_indicator()\n",
    "data_scaled['ADX'] = ta.trend.ADXIndicator(data_scaled['high'], data_scaled['low'], data_scaled['close']).adx()\n",
    "data_scaled['ATR'] = ta.volatility.AverageTrueRange(data_scaled['high'], data_scaled['low'], data_scaled['close']).average_true_range()\n",
    "data_scaled['Momentum'] = ta.momentum.AwesomeOscillatorIndicator(data_scaled['high'], data_scaled['low']).awesome_oscillator()\n",
    "data_scaled['Volume'] = data_scaled['volume']\n",
    "\n",
    "# Eliminar las filas con valores NaN\n",
    "data_scaled.dropna(inplace=True)\n",
    "\n",
    "X = np.array(data_scaled[['close', 't-24', 'RSI', 'MACD', 'EMA_100', 'EMA_200', 'ADX', 'ATR', 'Momentum', 'Volume']])\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "y = np.array(data_scaled['close'])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el modelo de red neuronal\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(100, return_sequences=True, input_shape=(X.shape[1], 1)),  # Aumenté las unidades en la LSTM\n",
    "    tf.keras.layers.LSTM(50, return_sequences=False),  # Añadí una segunda capa LSTM\n",
    "    tf.keras.layers.Dense(50, activation='relu'),  # Añadí una capa densa intermedia\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_val, y_val))  # Aumenté las epochs y ajusté el tamaño del batch\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save('ruta/para/guardar/el/modelo/btc_price_prediction_model_indicators.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
